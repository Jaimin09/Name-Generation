{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from myfunctionutils2 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select your file: Men/Women , short/whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_file = 'women_names_short.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representation of selected file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "X_names = np.genfromtxt(gender_file, dtype = 'str')\n",
    "X_names = np.array(X_names)\n",
    "print(X_names.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mary', 'anna', 'emma', 'elizabeth', 'minnie', 'margaret', 'ida',\n",
       "       'alice', 'bertha', 'sarah', 'annie', 'clara', 'ella', 'florence',\n",
       "       'cora', 'martha', 'laura', 'nellie', 'grace', 'carrie', 'maude',\n",
       "       'mabel', 'bessie', 'jennie', 'gertrude', 'julia', 'hattie',\n",
       "       'edith', 'mattie', 'rose', 'catherine', 'lillian', 'ada', 'lillie',\n",
       "       'helen', 'jessie', 'louise', 'ethel', 'lula', 'myrtle', 'eva',\n",
       "       'frances', 'lena', 'lucy', 'edna', 'maggie', 'pearl', 'daisy',\n",
       "       'fannie', 'josephine'], dtype='<U13')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_names[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making our dictionary/vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = sorted(set(open(gender_file, 'r').read().lower()))\n",
    "\n",
    "char_to_in = {ch:i for i,ch in enumerate(characters)}   #enumerate allow us to loop over something and have an automatic counter\n",
    "in_to_char = {i:ch for i, ch in enumerate(characters)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clip function for clipping gradient at end (if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip(gradients, maxValue):\n",
    "    dWaa, dWax, dWya, dba, dby = gradients['dWaa'], gradients['dWax'], gradients['dWya'], gradients['dba'], gradients['dby']\n",
    "    for gradient in [dWax, dWaa, dWya, dba, dby]:\n",
    "        np.clip(gradient, -maxValue, maxValue, out = gradient)\n",
    "        \n",
    "    gradients = {\"dWaa\": dWaa, \"dWax\": dWax, \"dWya\": dWya, \"dba\": dba, \"dby\": dby}\n",
    "    return gradients                                                                     #CHECKED OKK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(na, nx, ny):\n",
    "    Waa = np.random.randn(na, na)*0.01\n",
    "    Wax = np.random.randn(na, nx)*0.01\n",
    "    Wya = np.random.randn(ny, na)*0.01\n",
    "    ba = np.zeros((na, 1))\n",
    "    by = np.zeros((ny, 1))\n",
    "    \n",
    "    parameters = {\n",
    "        'Waa' : Waa,\n",
    "        'Wax' : Wax,\n",
    "        'Wya' : Wya,\n",
    "        'ba' : ba,\n",
    "        'by' : by,\n",
    "    }\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample for generating new words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_for_words(parameters, char_to_in):\n",
    "    Waa = parameters['Waa']\n",
    "    Wax = parameters['Wax']\n",
    "    Wya = parameters['Wya']\n",
    "    ba = parameters['ba']\n",
    "    by = parameters['by']\n",
    "    \n",
    "    vocab_size = 27\n",
    "    ind = -1\n",
    "    counter = 0\n",
    "    pred_indices = []\n",
    "    x = np.zeros((Wax.shape[1], 1))\n",
    "    a = np.zeros((Waa.shape[0],1))\n",
    "    \n",
    "    while(ind != 0 and counter != 50):\n",
    "        a = np.tanh(np.dot(Wax, x) + np.dot(Waa, a) + ba)\n",
    "        y = softmax(np.dot(Wya, a) + by)            # Can't use any other activation function as we are using ravel()\n",
    "             \n",
    "        ind = np.random.choice(list(range(vocab_size)), p = y.ravel())\n",
    "        pred_indices.append(ind)\n",
    "        \n",
    "        x = np.zeros((vocab_size, 1))\n",
    "        x[ind] = 1  \n",
    "        \n",
    "        counter += 1\n",
    "        if counter == 50:\n",
    "            pred_indices.append(0)\n",
    "            \n",
    "    return pred_indices                   #CHECKED OKK "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(X_i, Y_i, parameters, learning_rate):\n",
    "    loss, cache = rnn_forward(X_i, Y_i, parameters)\n",
    "    gradients, a = rnn_backward(X_i, Y_i, parameters, cache)\n",
    "    gradients = clip(gradients, maxValue = 5)\n",
    "    parameters = update_parameters(parameters, gradients, learning_rate)\n",
    "    \n",
    "    return loss, gradients, a[X_i.shape[0] - 1]                 #CHEKED OKK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_names, char_to_in, in_to_char, learning_rate = 0.01, iterations = 5, na = 100, n_pred_name = 5):\n",
    "    vocab_size = 27\n",
    "    nx, ny = vocab_size, vocab_size\n",
    "    parameters = initialize_parameters(na, nx, ny)\n",
    "    a_last = np.zeros((na, 1))\n",
    "    num_of_examples = X_names.shape[0]\n",
    "    \n",
    "    with open(gender_file) as f:\n",
    "        examples = f.readlines()     # Using this instead of array, takes much less time and does not hang with 50,000 examples\n",
    "    examples = [x.lower().strip() for x in examples]\n",
    "    \n",
    "    for m in range(num_of_examples*iterations):\n",
    "        m = m%(num_of_examples)\n",
    "        \n",
    "        X = [None] + [char_to_in[ch] for ch in examples[m]] \n",
    "        Y = X[1:] + [char_to_in[\"\\n\"]]\n",
    "        X = convert_indices_to_onehot(X)\n",
    "        Y = np.array(Y).reshape(X.shape[0], 1)\n",
    "        '''\n",
    "        X_element = X_names[m]\n",
    "        X_element = convert_name_to_indices(X_element, char_to_in)\n",
    "        Y_element = np.array(make_y_from_x(X_element))\n",
    "        Y_element = Y_element.reshape(Y_element.shape[0], 1)\n",
    "        X_element = np.vstack((np.zeros((1, 27)), convert_indices_to_onehot(X_element)))\n",
    "        '''\n",
    "        loss, gradients, a_last = optimize(X, Y, parameters, learning_rate)\n",
    "\n",
    "        if m%(num_of_examples/5)==0:\n",
    "            print(\"Loss is  :\", loss[0],'\\n')\n",
    "            for n in range(n_pred_name):\n",
    "                sample_indices = sample_for_words(parameters, char_to_in)\n",
    "                for index in sample_indices:\n",
    "                    print(in_to_char[index], end = '')\n",
    "            print('\\n')\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is  : 16.479136333696434 \n",
      "\n",
      "oeugkelw\n",
      "tcnyrqdoqccfiijxjcugwoxgxlssbamwbdjrzuxxpojszreorj\n",
      "yfgwpvnxntruufmlldaqzxywdmpsml\n",
      "f\n",
      "lbiyryloctvsnbtcw\n",
      "\n",
      "\n",
      "Loss is  : 12.62020322958768 \n",
      "\n",
      "qabia\n",
      "alsersa\n",
      "szldne\n",
      "ravitd\n",
      "rrla\n",
      "\n",
      "\n",
      "Loss is  : 10.079953756290417 \n",
      "\n",
      "lgona\n",
      "hanva\n",
      "mattia\n",
      "bsovet\n",
      "elie\n",
      "\n",
      "\n",
      "Loss is  : 14.669130596639283 \n",
      "\n",
      "jandie\n",
      "rode\n",
      "faris\n",
      "cetieta\n",
      "helxna\n",
      "\n",
      "\n",
      "Loss is  : 12.93610377326382 \n",
      "\n",
      "rle\n",
      "hatie\n",
      "elmothie\n",
      "vistie\n",
      "emdisa\n",
      "\n",
      "\n",
      "Loss is  : 8.869411784204248 \n",
      "\n",
      "estie\n",
      "iverda\n",
      "arnie\n",
      "emdal\n",
      "iva\n",
      "\n",
      "\n",
      "Loss is  : 8.66241311063053 \n",
      "\n",
      "esulanni\n",
      "hrusa\n",
      "jatie\n",
      "arniad\n",
      "emxia\n",
      "\n",
      "\n",
      "Loss is  : 7.858406469236952 \n",
      "\n",
      "deline\n",
      "wina\n",
      "mattie\n",
      "eleona\n",
      "murill\n",
      "\n",
      "\n",
      "Loss is  : 14.128514511418109 \n",
      "\n",
      "alpha\n",
      "dachalan\n",
      "mella\n",
      "eresea\n",
      "elda\n",
      "\n",
      "\n",
      "Loss is  : 11.24236357301068 \n",
      "\n",
      "delvie\n",
      "kith\n",
      "essal\n",
      "mette\n",
      "annetne\n",
      "\n",
      "\n",
      "Loss is  : 8.080122173101556 \n",
      "\n",
      "aabe\n",
      "lenna\n",
      "dore\n",
      "gusssia\n",
      "elidie\n",
      "\n",
      "\n",
      "Loss is  : 8.311826540433504 \n",
      "\n",
      "sura\n",
      "aura\n",
      "cocenna\n",
      "attauda\n",
      "lea\n",
      "\n",
      "\n",
      "Loss is  : 6.649523669334731 \n",
      "\n",
      "cjanrie\n",
      "cdarmen\n",
      "doda\n",
      "elie\n",
      "elout\n",
      "\n",
      "\n",
      "Loss is  : 13.413729885775648 \n",
      "\n",
      "lille\n",
      "arthell\n",
      "bichie\n",
      "jone\n",
      "elerie\n",
      "\n",
      "\n",
      "Loss is  : 9.475752150856053 \n",
      "\n",
      "tina\n",
      "penaggrean\n",
      "ceatahese\n",
      "minka\n",
      "deul\n",
      "\n",
      "\n",
      "Loss is  : 8.751162769970623 \n",
      "\n",
      "augena\n",
      "deana\n",
      "siphenie\n",
      "leva\n",
      "reshor\n",
      "\n",
      "\n",
      "Loss is  : 7.396302455587603 \n",
      "\n",
      "farelet\n",
      "nata\n",
      "eusa\n",
      "peurine\n",
      "eutheca\n",
      "\n",
      "\n",
      "Loss is  : 6.445449359500607 \n",
      "\n",
      "cmyrty\n",
      "clea\n",
      "dellie\n",
      "bell\n",
      "marie\n",
      "\n",
      "\n",
      "Loss is  : 13.248577282327732 \n",
      "\n",
      "adelan\n",
      "persoenela\n",
      "salla\n",
      "corrocilo\n",
      "dotha\n",
      "\n",
      "\n",
      "Loss is  : 9.683180813219868 \n",
      "\n",
      "gella\n",
      "mabdelie\n",
      "lotine\n",
      "angia\n",
      "rosian\n",
      "\n",
      "\n",
      "Loss is  : 8.796424974963344 \n",
      "\n",
      "mina\n",
      "margary\n",
      "lenna\n",
      "vinnie\n",
      "catheria\n",
      "\n",
      "\n",
      "Loss is  : 6.671974723191201 \n",
      "\n",
      "hanniettil\n",
      "henriet\n",
      "zottin\n",
      "male\n",
      "zues\n",
      "\n",
      "\n",
      "Loss is  : 5.686324264283813 \n",
      "\n",
      "alline\n",
      "meline\n",
      "arnta\n",
      "marine\n",
      "klicen\n",
      "\n",
      "\n",
      "Loss is  : 15.084208131464209 \n",
      "\n",
      "albelan\n",
      "erneda\n",
      "arhie\n",
      "elwsie\n",
      "sudare\n",
      "\n",
      "\n",
      "Loss is  : 10.219492895014673 \n",
      "\n",
      "mortie\n",
      "freyk\n",
      "annon\n",
      "trie\n",
      "ela\n",
      "\n",
      "\n",
      "The time is 2.94: minutes\n"
     ]
    }
   ],
   "source": [
    "stime = time.time()\n",
    "parameters = model(X_names[:10000], char_to_in, in_to_char, learning_rate = 0.01,  na = 50, iterations = 5)\n",
    "etime = time.time()\n",
    "times = (etime-stime)/60\n",
    "print(\"The time is %.2f:\" %times, \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
